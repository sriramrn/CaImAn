{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Here we will be focusing more on the cnmf part and its main functions <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if __IPYTHON__:\n",
    "        # this is used for debugging purposes only. allows to reload classes when changed\n",
    "        get_ipython().magic(u'load_ext autoreload')\n",
    "        get_ipython().magic(u'autoreload 2')\n",
    "except NameError:       \n",
    "    print('Not IPYTHON')    \n",
    "    pass\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.sparse import coo_matrix\n",
    "import psutil\n",
    "import glob\n",
    "import os\n",
    "import scipy\n",
    "from ipyparallel import Client\n",
    "#import matplotlib as mpl\n",
    "#mpl.use('TkAgg')\n",
    "\n",
    "import pylab as pl\n",
    "#pl.ion()\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.components_evaluation import evaluate_components\n",
    "from caiman.utils.visualization import plot_contours,view_patches_bar,nb_plot_contour,nb_view_patches\n",
    "from caiman.base.rois import extract_binary_masks_blob\n",
    "import caiman.source_extraction.cnmf as cnmf\n",
    "from caiman.utils.utils import download_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import bokeh.plotting as bp\n",
    "import bokeh.plotting as bpl\n",
    "try:\n",
    "       from bokeh.io import vform, hplot\n",
    "except:\n",
    "       # newer version of bokeh does not use vform & hplot, instead uses column & row\n",
    "       from bokeh.layouts import column as vform\n",
    "       from bokeh.layouts import row as hplot\n",
    "from bokeh.models import CustomJS, ColumnDataSource, Slider\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cmap\n",
    "import numpy as np\n",
    "\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using the workload manager SLURM </h1> \n",
    "to have an extensive use of the machine. \n",
    "<p> This is to be used when working with a cluster of machines \n",
    "<img src=\"docs/img/Dockerfile.gif\"/>\n",
    "</p><p>This will put dispatch and manage the workload gave by the algorithm : <img src=\"docs/img/node.gif\" /></p>\n",
    "<p> learn more : <em> https://slurm.schedmd.com/overview.html </em> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frame rate in Hz\n",
    "final_frate=10 \n",
    "#backend='SLURM'\n",
    "backend='local'\n",
    "if backend == 'SLURM':\n",
    "    n_processes = np.int(os.environ.get('SLURM_NPROCS'))\n",
    "else:\n",
    "    n_processes = np.maximum(np.int(psutil.cpu_count()),1) # roughly number of cores on your machine minus 1\n",
    "print('using ' + str(n_processes) + ' processes')\n",
    "#%% start cluster for efficient computation\n",
    "single_thread=False\n",
    "\n",
    "if single_thread:\n",
    "    dview=None\n",
    "else:    \n",
    "    try:\n",
    "        c.close()\n",
    "    except:\n",
    "        print('C was not existing, creating one')\n",
    "    print(\"Stopping  cluster to avoid unnencessary use of memory....\")\n",
    "    sys.stdout.flush()  \n",
    "    if backend == 'SLURM':\n",
    "        try:\n",
    "            cm.stop_server(is_slurm=True)\n",
    "        except:\n",
    "            print('Nothing to stop')\n",
    "        slurm_script='/mnt/xfs1/home/agiovann/SOFTWARE/Constrained_NMF/SLURM/slurmStart.sh'\n",
    "        cm.start_server(slurm_script=slurm_script)\n",
    "        pdir, profile = os.environ['IPPPDIR'], os.environ['IPPPROFILE']\n",
    "        c = Client(ipython_dir=pdir, profile=profile)        \n",
    "    else:\n",
    "        cm.stop_server()\n",
    "        cm.start_server()        \n",
    "        c=Client()\n",
    "\n",
    "    print('Using '+ str(len(c)) + ' processes')\n",
    "    dview=c[:len(c)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We can see here that the number of processes are the number of core your computer possess. <br/> Your computer can be seen as a node that possess X cores </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Memory mapping files in F order</h1>\n",
    "<p> see : https://github.com/simonsfoundation/CaImAn/blob/master/demo_caiman_pipeline.ipynb </p>\n",
    "<img src=\"docs/img/Fordermmap.png\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% FOR LOADING ALL TIFF FILES IN A FILE AND SAVING THEM ON A SINGLE MEMORY MAPPABLE FILE\n",
    "fnames=['demoMovieJ.tif']\n",
    "base_folder='./example_movies/' # folder containing the demo files\n",
    "# %% download movie if not there                                                                                                                                                                                \n",
    "if fnames[0] in ['Sue_2x_3000_40_-46.tif','demoMovieJ.tif']:\n",
    "    # TODO: todocument                                                                                                                                                                                          \n",
    "    download_demo(fnames[0])\n",
    "    fnames = [os.path.join('example_movies',fnames[0])]\n",
    "# TODO: todocument                                                                                                                                                                                              \n",
    "m_orig = cm.load_movie_chain(fnames[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "downsample_factor=1 # use .2 or .1 if file is large and you want a quick answer\n",
    "final_frate=final_frate*downsample_factor\n",
    "idx_xy=None\n",
    "base_name='Yr'\n",
    "name_new=cm.save_memmap_each(fnames\n",
    "        , dview=dview,base_name=base_name, resize_fact=(1, 1, downsample_factor)\n",
    "        , remove_init=0,idx_xy=idx_xy )\n",
    "name_new.sort()\n",
    "fname_new=cm.save_memmap_join(name_new,base_name='Yr', n_chunks=12, dview=dview)\n",
    "print(fnames)\n",
    "print(fname_new)\n",
    "print (\"\\n we can see we are loading the file (line1) into a memorymapped object (line2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Correlation image </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "Yr,dims,T=cm.load_memmap(fname_new)\n",
    "Y=np.reshape(Yr,dims+(T,),order='F')\n",
    "#%% visualize correlation image\n",
    "Cn = cm.local_correlations(Y)\n",
    "pl.imshow(Cn,cmap='gray') \n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%% parameters of experiment\n",
    "K=30 # number of neurons expected per patch\n",
    "gSig=[6,6] # expected half size of neurons\n",
    "merge_thresh=0.8 # merging threshold, max correlation allowed\n",
    "p=2 #order of the autoregressive system\n",
    "options = cnmf.utilities.CNMFSetParms(Y\n",
    "        ,n_processes,p=p,gSig=gSig,K=K,ssub=2,tsub=2, normalize_init=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " CNMFSetParms define Dictionaries of CNMF parameters.\n",
    " Any parameter that is not set get a default value specified.\n",
    " \n",
    "     each dictionnary is used by different part of the CNMF process : \n",
    " - init_paramters\n",
    " - pre_processing_parameters\n",
    " - patch_parameters\n",
    " - spatial_parameters\n",
    " - temporal_parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing of the datas and initialization of the components </h2>\n",
    "<ul><li> here, we compute the mean of the noise spectral density </li>\n",
    "<li> then, we initialize each component with a greedy ROI algorithm on component that have been spatially filter using a gaussian kernel </li>\n",
    "<li> we then further update the component using Hals method on the newly obtained nmf paramters</ul>\n",
    "<p> see More : NMF AND ROI :http://www.cell.com/neuron/fulltext/S0896-6273(15)01084-3<br\\> </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Yr,sn,g,psx = cnmf.pre_processing.preprocess_data(Yr\n",
    "            ,dview=dview\n",
    "            ,n_pixels_per_process=100,  noise_range = [0.25,0.5]\n",
    "            ,noise_method = 'logmexp', compute_g=False,  p = 2,\n",
    "             lags = 5, include_noise = False, pixels = None\n",
    "            ,max_num_samples_fft=3000, check_nan = True)\n",
    "\n",
    "Ain, Cin, b_in, f_in, center=cnmf.initialization.initialize_components(Y\n",
    "            ,K=30, gSig=[5, 5], gSiz=None, ssub=1, tsub=1, nIter=5, maxIter=5, nb=1\n",
    "            , use_hals=False, normalize_init=True, img=None, method='greedy_roi'\n",
    "            , max_iter_snmf=500, alpha_snmf=10e2, sigma_smooth_snmf=(.5, .5, .5)\n",
    "            , perc_baseline_snmf=20)\n",
    "p1=nb_plot_contour(Cn,Ain,dims[0],dims[1],thr=0.9,face_color=None\n",
    "                    , line_color='black',alpha=0.4,line_width=2)\n",
    "bpl.show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> HALS </h2>\n",
    "we want to minimize\n",
    "<img src=docs/img/hals1.png width=300px/>\n",
    "updating parameters\n",
    "<img src=docs/img/hals2.png width=300px />\n",
    "<p>HALS : http://proceedings.mlr.press/v39/kimura14.pdf</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ain, Cin, b_in, f_in = cnmf.initialization.hals(Y, Ain, Cin, b_in, f_in, maxIter=5)\n",
    "p1=nb_plot_contour(Cn,Ain,dims[0],dims[1],thr=0.9,face_color=None\n",
    "                    , line_color='black',alpha=0.4,line_width=2)\n",
    "bpl.show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%% UPDATE SPATIAL COMPONENTS\n",
    "pl.close()\n",
    "t1 = time()\n",
    "A,b,Cin,f_in = cnmf.spatial.update_spatial_components(Yr, Cin, f_in, Ain, sn=sn, dview=dview,**options['spatial_params'])\n",
    "t_elSPATIAL = time() - t1\n",
    "print(t_elSPATIAL)\n",
    "#clear_output(wait=True)\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pl.figure(num=None, figsize=(9, 7), dpi=100, facecolor='w', edgecolor='k')\n",
    "crd = plot_contours(A,Cn,thr=0.9)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p1=nb_plot_contour(Cn,A.todense(),dims[0],dims[1],thr=0.9,face_color=None, line_color='black',alpha=0.4,line_width=2)\n",
    "bpl.show(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pl.close()\n",
    "t1 = time()\n",
    "options['temporal_params']['p'] = 0 # set this to zero for fast updating without deconvolution\n",
    "C,A,b,f,S,bl,c1,neurons_sn,g,YrA = cnmf.temporal.update_temporal_components(Yr,A,b,Cin,f_in,bl=None,c1=None,sn=None,g=None,**options['temporal_params'])\n",
    "t_elTEMPORAL = time() - t1\n",
    "print(t_elTEMPORAL)\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%% merge components corresponding to the same neuron\n",
    "t1 = time()\n",
    "A_m,C_m,nr_m,merged_ROIs,S_m,bl_m,c1_m,sn_m,g_m=cnmf.merging.merge_components(Yr,A,b,C,f,S,sn,options['temporal_params'], options['spatial_params'],dview=dview, bl=bl, c1=c1, sn=neurons_sn, g=g, thr=merge_thresh, mx=50, fast_merge = True)\n",
    "t_elMERGE = time() - t1\n",
    "print(t_elMERGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#refine spatial and temporal components\n",
    "pl.close()\n",
    "t1 = time()\n",
    "A2,b2,C2,f = cnmf.spatial.update_spatial_components(Yr, C_m, f, A_m, sn=sn,dview=dview, **options['spatial_params'])\n",
    "options['temporal_params']['p'] = p # set it back to original value to perform full deconvolution\n",
    "C2,A2,b2,f2,S2,bl2,c12,neurons_sn2,g21,YrA = cnmf.temporal.update_temporal_components(Yr,A2,b2,C2,f,dview=dview, bl=None,c1=None,sn=None,g=None,**options['temporal_params'])\n",
    "clear_output(wait=True)\n",
    "print(time() - t1) # 100 seconds\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tB = np.minimum(-2,np.floor(-5./30*final_frate))\n",
    "tA = np.maximum(5,np.ceil(25./30*final_frate))\n",
    "Npeaks=10\n",
    "traces=C2+YrA\n",
    "#        traces_a=traces-scipy.ndimage.percentile_filter(traces,8,size=[1,np.shape(traces)[-1]/5])\n",
    "#        traces_b=np.diff(traces,axis=1)\n",
    "fitness_raw, fitness_delta, erfc_raw, erfc_delta, r_values, significant_samples = \\\n",
    "    evaluate_components(Y, traces, A2, C2, b2, f2, final_frate, remove_baseline=True,\n",
    "                                      N=5, robust_std=False, Athresh=0.1, Npeaks=Npeaks,  thresh_C=0.3)\n",
    "    \n",
    "idx_components_r=np.where(r_values>=.6)[0]\n",
    "idx_components_raw=np.where(fitness_raw<-60)[0]        \n",
    "idx_components_delta=np.where(fitness_delta<-20)[0]   \n",
    "\n",
    "\n",
    "min_radius=gSig[0]-2\n",
    "masks_ws,idx_blobs,idx_non_blobs=extract_binary_masks_blob(\n",
    "A2.tocsc(), min_radius, dims, num_std_threshold=1, \n",
    "minCircularity= 0.6, minInertiaRatio = 0.2,minConvexity =.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "idx_components=np.union1d(idx_components_r,idx_components_raw)\n",
    "idx_components=np.union1d(idx_components,idx_components_delta)  \n",
    "idx_blobs=np.intersect1d(idx_components,idx_blobs)   \n",
    "idx_components_bad=np.setdiff1d(range(len(traces)),idx_components)\n",
    "clear_output(wait=True)\n",
    "print(' ***** ')\n",
    "print(len(traces))\n",
    "print(len(idx_components))\n",
    "print(len(idx_blobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fg=pl.figure(figsize=(12,20))\n",
    "pl.subplot(1,2,1)\n",
    "crd = plot_contours(A2.tocsc()[:,idx_components],Cn,thr=0.9)\n",
    "pl.subplot(1,2,2)\n",
    "crd = plot_contours(A2.tocsc()[:,idx_components_bad],Cn,thr=0.9)\n",
    "print(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p2=nb_plot_contour(Cn,A2.tocsc()[:,idx_components].todense(),dims[0],dims[1],thr=0.9,face_color='purple', line_color='black',alpha=0.3,line_width=2)\n",
    "bpl.show(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discard_traces_fluo=nb_view_patches(Yr,A2.tocsc()[:,idx_components],C2[idx_components],b2,f2,dims[0],dims[1],thr = 0.8,image_neurons=Cn, denoised_color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discard_traces_fluo=nb_view_patches(Yr,A2.tocsc()[:,idx_components_bad],C2[idx_components_bad],b2,f2,dims[0],dims[1],thr = 0.8,image_neurons=Cn, denoised_color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done\n"
     ]
    }
   ],
   "source": [
    "#%% STOP CLUSTER\n",
    "cm.stop_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
