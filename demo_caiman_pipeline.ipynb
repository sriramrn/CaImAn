{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"content-type\"><style type=\"text/css\">ol</style></head><body class=\"c5\"><p class=\"c0 c4\"><span class=\"c3\"></span></p><p class=\"c2 title\" id=\"h.rrbabt268i6e\"><h1>CaImAn&rsquo;s Demo pipeline</h1></p><p class=\"c0\"><span class=\"c3\">This notebook will help to demonstrate the process of CaImAn and how it uses different functions to denoise, deconvolve and demix neurons from a Calcium Imaging Video. </span></p>\n",
    "<p><img src=\"docs/img/quickintro.png\" /></p>\n",
    "<p class=\"c0\"><span class=\"c3\">More information can be found in CaImAn&rsquo;s documentation. </span></p>\n",
    "</html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Nov 21 15:53:15 2016\n",
    "\n",
    "@author: agiovann\n",
    "\"\"\"\n",
    "from IPython.display import YouTubeVideo as yt\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from builtins import zip\n",
    "from builtins import str\n",
    "from builtins import map\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "import cv2\n",
    "try:\n",
    "    cv2.setNumThreads(1)\n",
    "except:\n",
    "    print('Open CV is naturally single threaded')\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        print((1))\n",
    "        # this is used for debugging purposes only. allows to reload classes\n",
    "        # when changed\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    print('Not IPYTHON')\n",
    "    pass\n",
    "#%%\n",
    "import caiman as cm\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pylab as pl\n",
    "import psutil\n",
    "import sys\n",
    "from ipyparallel import Client\n",
    "from skimage.external.tifffile import TiffFile\n",
    "import scipy\n",
    "#%%\n",
    "from caiman.motion_correction import tile_and_correct, motion_correction_piecewise\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.components_evaluation import evaluate_components \n",
    "from caiman.utils.visualization import plot_contours, view_patches_bar\n",
    "from caiman.base.rois import extract_binary_masks_blob\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours,view_patches_bar,nb_plot_contour,nb_view_patches\n",
    "import bokeh.plotting as bpl\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "#m = cm.load('example_movies/demoMovie.tif')\n",
    "#\n",
    "#cm.concatenate([m.resize(1,1,.2),m.resize(1,1,.2)],axis =1).play(fr =20, gain = 3.,magnification =3)\n",
    "#%% set parameters and create template by RIGID MOTION CORRECTION\n",
    "params_movie = {'fname': ['Sue_2x_3000_40_-46.tif'],\n",
    "                'niter_rig': 1,\n",
    "                'max_shifts': (6, 6),  # maximum allow rigid shift\n",
    "                'splits_rig': 56,  # for parallelization split the movies in  num_splits chuncks across time\n",
    "                # if none all the splits are processed and the movie is saved\n",
    "                'num_splits_to_process_rig': None,\n",
    "                # intervals at which patches are laid out for motion correction\n",
    "                'strides': (48, 48),\n",
    "                # overlap between pathes (size of patch strides+overlaps)\n",
    "                'overlaps': (24, 24),\n",
    "                'splits_els': 56,  # for parallelization split the movies in  num_splits chuncks across time\n",
    "                # if none all the splits are processed and the movie is saved\n",
    "                'num_splits_to_process_els': [28, None],\n",
    "                'upsample_factor_grid': 4,  # upsample factor to avoid smearing when merging patches\n",
    "                # maximum deviation allowed for patch with respect to rigid\n",
    "                # shift\n",
    "                'max_deviation_rigid': 3,\n",
    "                'p': 1,  # order of the autoregressive system\n",
    "                'merge_thresh': 0.8,  # merging threshold, max correlation allowed\n",
    "                'rf': 15,  # half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "                'stride_cnmf': 6,  # amounpl.it of overlap between the patches in pixels\n",
    "                'K': 4,  # number of components per patch\n",
    "                # if dendritic. In this case you need to set init_method to\n",
    "                # sparse_nmf\n",
    "                'is_dendrites': False,\n",
    "                'init_method': 'greedy_roi',\n",
    "                'gSig': [4, 4],  # expected half size of neurons\n",
    "                'alpha_snmf': None,  # this controls sparsity\n",
    "                'final_frate': 30\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% parameters from dictionary\n",
    "fname = params_movie['fname']\n",
    "niter_rig = params_movie['niter_rig']\n",
    "# maximum allow rigid shift\n",
    "max_shifts = params_movie['max_shifts']  \n",
    "# for parallelization split the movies in  num_splits chuncks across time\n",
    "splits_rig = params_movie['splits_rig']  \n",
    "# if none all the splits are processed and the movie is saved\n",
    "num_splits_to_process_rig = params_movie['num_splits_to_process_rig']\n",
    "# intervals at which patches are laid out for motion correction\n",
    "strides = params_movie['strides']\n",
    "# overlap between pathes (size of patch strides+overlaps)\n",
    "overlaps = params_movie['overlaps']\n",
    "# for parallelization split the movies in  num_splits chuncks across time\n",
    "splits_els = params_movie['splits_els'] \n",
    "# if none all the splits are processed and the movie is saved\n",
    "num_splits_to_process_els = params_movie['num_splits_to_process_els']\n",
    "# upsample factor to avoid smearing when merging patches\n",
    "upsample_factor_grid = params_movie['upsample_factor_grid'] \n",
    "# maximum deviation allowed for patch with respect to rigid\n",
    "# shift\n",
    "max_deviation_rigid = params_movie['max_deviation_rigid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %% download movie if not there                                                                                                                                                                                \n",
    "if fname[0] in ['Sue_2x_3000_40_-46.tif','demoMovieJ.tif']:\n",
    "    # TODO: todocument                                                                                                                                                                                          \n",
    "    download_demo(fname[0])\n",
    "    fname = [os.path.join('example_movies',fname[0])]\n",
    "# TODO: todocument                                                                                                                                                                                              \n",
    "m_orig = cm.load_movie_chain(fname[:1])\n",
    "\n",
    "yt(\"I1yc8LLwI-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load movie (in memory!)\n",
    "m_orig = cm.load_movie_chain(fname)\n",
    "#%% play movie\n",
    "downsample_ratio = .2\n",
    "offset_mov = -np.min(m_orig[:100])\n",
    "m_orig.resize(1, 1, downsample_ratio).play(\n",
    "    gain=10, offset = offset_mov, fr=30, magnification=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>some of the pixels in this movie are negative, we then need to make them positive </em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Motion correction is performed in parallel on chunks taken across times. </h2>\n",
    "<p> Create temporal chunks of the movie for  parallel processing on all cores </p>\n",
    "<p> ipyparallel is used to create a cluster that handles the parallelization eithr on the PC ( see : https://ipyparallel.readthedocs.io/en/latest/intro.html) or on clusters interfacing with slurm ( see : https://slurm.schedmd.com/quickstart.html ) </p>\n",
    "<p><img src=\"docs/img/cordermmap.png\" /> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start the cluster\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Rigid motion correction</h1>\n",
    "<p> Rigid motion correction is performed using template matching to a reference image via cross-correlations. For each frame a displacement vector along x and y is calculated and applied. The template image (usually the median of each image over time) is updated each time the movie is corrected to increase its precision. </p>\n",
    "<img src=\"docs/img/rigidcorrection.png\" />\n",
    "more info : <em> http://opencv.org/about.html </em>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie must be mostly positive for this to work\n",
    "min_mov = cm.load(fname[0], subindices=range(400)).min()\n",
    "\n",
    "mc = MotionCorrect(fname[0], min_mov,\n",
    "                   dview=dview, max_shifts=max_shifts, niter_rig=niter_rig, splits_rig=splits_rig, \n",
    "                   num_splits_to_process_rig=num_splits_to_process_rig, \n",
    "                strides= strides, overlaps= overlaps, splits_els=splits_els,\n",
    "                num_splits_to_process_els=num_splits_to_process_els, \n",
    "                upsample_factor_grid=upsample_factor_grid, max_deviation_rigid=max_deviation_rigid, \n",
    "      \n",
    "                shifts_opencv = True, nonneg_movie = True)\n",
    "#%%\n",
    "mc.motion_correct_rigid(save_movie=True)\n",
    "# load motion corrected movie\n",
    "m_rig = cm.load(mc.fname_tot_rig)\n",
    "bord_px_rig = np.ceil(np.max(mc.shifts_rig)).astype(np.int)\n",
    "#%% visualize templates\n",
    "pl.imshow(mc.total_template_rig, cmap = 'gray')\n",
    "#%% inspect movie\n",
    "m_rig.resize(1, 1, downsample_ratio).play(\n",
    "    gain=10, offset = offset_mov*.25, fr=30, magnification=2,bord_px = bord_px_rig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Inspect motion correction results</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot rigid shifts\n",
    "pl.close()\n",
    "pl.plot(mc.shifts_rig)\n",
    "pl.legend(['x shifts','y shifts'])\n",
    "pl.xlabel('frames')\n",
    "pl.ylabel('pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Piecewise rigid motion correction </h1>\n",
    "<p> When the motion is not adequately described by rigid tranlsation, we adopt a piecewise rigid correction approach<p>\n",
    "<img src=\"docs\\img\\pwrigidcorrection.png\" />\n",
    "<p> more info : </p>\n",
    "<em> http://biorxiv.org/content/biorxiv/early/2017/02/14/108514.full.pdf </em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% motion correct piecewise rigid\n",
    "mc.motion_correct_pwrigid(save_movie=True, template=mc.total_template_rig, show_template = True)\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "pl.imshow(mc.total_template_els, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% visualize elastic shifts\n",
    "pl.close()\n",
    "pl.figure(figsize = (20,10))\n",
    "pl.subplot(2, 1, 1)\n",
    "pl.plot(mc.x_shifts_els)\n",
    "pl.ylabel('x shifts (pixels)')\n",
    "pl.subplot(2, 1, 2)\n",
    "pl.plot(mc.y_shifts_els)\n",
    "pl.ylabel('y_shifts (pixels)')\n",
    "pl.xlabel('frames')\n",
    "#%% compute borders to exclude\n",
    "bord_px_els = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                                 np.max(np.abs(mc.y_shifts_els)))).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check movie\n",
    "downsample_ratio = .2\n",
    "m_els.resize(1, 1, downsample_ratio).play(\n",
    "    gain=10, offset = 0, fr=30, magnification=2,bord_px = bord_px_els)\n",
    "# compare with original and rigid corrected movies\n",
    "downsample_factor = .2\n",
    "cm.concatenate([m_orig.resize(1, 1, downsample_factor)+offset_mov, m_rig.resize(1, 1, downsample_factor), m_els.resize(\n",
    "    1, 1, downsample_factor)], axis=2).play(fr=60, gain=15, magnification=2, offset=0)\n",
    "#%% local correlation\n",
    "pl.figure(figsize = (20,10))\n",
    "pl.imshow(m_els.local_correlations(eight_neighbours=True, swap_dim=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Assessing Motion correction Quality </h1>\n",
    "for the raw, rigid corrected and piecewise rigid corrected videos\n",
    "<p> using smoothness <em> (mean over time) </em> </p>\n",
    "--------------\n",
    "<p> using correlation to the template <em> (Pearson Correlation coefficient)</em> </p> \n",
    "--------------\n",
    "see : http://docs.opencv.org/2.4/doc/tutorials/imgproc/histograms/template_matching/template_matching.html ( like a normalized SSD )\n",
    "<p> optical flow : </p>\n",
    "--------------\n",
    "<img src=\"docs/img/opticalflow.png\" />\n",
    "more info :<em> http://docs.opencv.org/trunk/d7/d8b/tutorial_py_lucas_kanade.html </em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% compute metrics for the results (TAKES TIME!!)\n",
    "final_size = np.subtract(mc.total_template_els.shape, 2 * bord_px_els)\n",
    "winsize = 100\n",
    "swap_dim = False\n",
    "resize_fact_flow = .2\n",
    "tmpl, correlations, flows_orig, norms, smoothness = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    mc.fname_tot_els, final_size[0], final_size[1], swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)\n",
    "tmpl, correlations, flows_orig, norms, smoothness = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    mc.fname_tot_rig, final_size[0], final_size[1], swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)\n",
    "tmpl, correlations, flows_orig, norms, smoothness = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    fname[0], final_size[0], final_size[1], swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot the results of metrics\n",
    "fls = [mc.fname_tot_els[:-4] + '_metrics.npz', mc.fname_tot_rig[:-4] +\n",
    "       '_metrics.npz', mc.fname[:-4] + '_metrics.npz']\n",
    "#%%\n",
    "pl.figure(figsize = (20,10))\n",
    "for cnt, fl, metr in zip(range(len(fls)),fls,['pw_rigid','rigid','raw']):\n",
    "    with np.load(fl) as ld:\n",
    "        print(ld.keys())\n",
    "#        pl.figure()\n",
    "        print(fl)\n",
    "        print(str(np.mean(ld['norms'])) + '+/-' + str(np.std(ld['norms'])) +\n",
    "              ' ; ' + str(ld['smoothness']) + ' ; ' + str(ld['smoothness_corr']))\n",
    "        \n",
    "        pl.subplot(len(fls), 4, 1 + 4 * cnt)\n",
    "        pl.ylabel(metr)\n",
    "        try:\n",
    "            mean_img = np.mean(\n",
    "            cm.load(fl[:-12] + 'mmap'), 0)[12:-12, 12:-12]\n",
    "        except:\n",
    "            try:\n",
    "                mean_img = np.mean(\n",
    "                    cm.load(fl[:-12] + '.tif'), 0)[12:-12, 12:-12]\n",
    "            except:\n",
    "                mean_img = np.mean(\n",
    "                    cm.load(fl[:-12] + 'hdf5'), 0)[12:-12, 12:-12]\n",
    "                    \n",
    "        lq, hq = np.nanpercentile(mean_img, [.5, 99.5])\n",
    "        pl.imshow(mean_img, vmin=lq, vmax=hq)\n",
    "        pl.title('Mean')\n",
    "        #        pl.plot(ld['correlations'])\n",
    "\n",
    "        pl.subplot(len(fls), 4, 4 * cnt + 2)\n",
    "        pl.imshow(ld['img_corr'], vmin=0, vmax=.35)\n",
    "        pl.title('Corr image')\n",
    "    #        pl.colorbar()\n",
    "        pl.subplot(len(fls), 4, 4 * cnt + 3)\n",
    "    #\n",
    "        pl.plot(ld['norms'])\n",
    "        pl.xlabel('frame')\n",
    "        pl.ylabel('norm opt flow')\n",
    "        pl.subplot(len(fls), 4, 4 * cnt + 4)\n",
    "        flows = ld['flows']\n",
    "        pl.imshow(np.mean(\n",
    "        np.sqrt(flows[:, :, :, 0]**2 + flows[:, :, :, 1]**2), 0), vmin=0, vmax=0.3)\n",
    "        pl.colorbar()\n",
    "        pl.title('Mean optical flow')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Memory mapping </h1>\n",
    "<p> In order to reduce memory usage and parallelize, we run in parallel the algorithm on spatially overlapping patches of the movie.</p>\n",
    "<p><img src=\"docs/img/fordermmap.png\" /></p>\n",
    "<h3> Data is saved on drive so that extracting blocks of movies is efficient.  </h3>\n",
    "<p>Data can be either quickly read per columns or per rows but not in both directions. So, we save the movie in such a way that it is easy to read across time.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEMORY MAPPING: save each chunk in F format on memory mapped files\n",
    "if 'max_shifts' not in params_movie:\n",
    "    fnames = [params_movie['fname']]\n",
    "    border_to_0 = 0\n",
    "elif not 'overlaps'in params_movie:\n",
    "    fnames = [mc.fname_tot_rig]\n",
    "    border_to_0 = bord_px_rig\n",
    "    m_els = m_rig\n",
    "else:\n",
    "    fnames = [mc.fname_tot_els]\n",
    "    border_to_0 = bord_px_els\n",
    "    \n",
    "# if you need to crop the borders use slicing    \n",
    "# idx_x=slice(border_nan,-border_nan,None)\n",
    "# idx_y=slice(border_nan,-border_nan,None)\n",
    "# idx_xy=(idx_x,idx_y)\n",
    "idx_xy = None\n",
    "add_to_movie = -np.nanmin(m_els) + 1  # movie must be positive\n",
    "# if you need to remove frames from the beginning of each file\n",
    "remove_init = 0\n",
    "# downsample movie in time: use .2 or .1 if file is large and you want a quick answer             \n",
    "downsample_factor = 1 \n",
    "base_name = fname[0].split('/')[-1][:-4]\n",
    "name_new = cm.save_memmap_each(fnames, dview=dview, base_name=base_name, resize_fact=(\n",
    "    1, 1, downsample_factor), remove_init=remove_init, idx_xy=idx_xy, add_to_movie=add_to_movie, border_to_0=border_to_0)\n",
    "name_new.sort()\n",
    "print(name_new)\n",
    "\n",
    "#%% concatenate chunks if needed\n",
    "if len(name_new) > 1:\n",
    "    fname_new = cm.save_memmap_join(\n",
    "        name_new, base_name='Yr', n_chunks=12, dview=dview)\n",
    "else:\n",
    "    print('One file only, not saving!')\n",
    "    fname_new = name_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% LOAD MEMMAP FILE\n",
    "# fname_new='Yr_d1_501_d2_398_d3_1_order_F_frames_369_.mmap'\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "d1, d2 = dims\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "Y = np.reshape(Yr, dims + (T,), order='F')\n",
    "m_images = cm.movie(images)\n",
    "#%%  checks on movies (might take time if large!)\n",
    "if np.min(images) < 0:\n",
    "    raise Exception('Movie too negative, add_to_movie should be larger')\n",
    "if np.sum(np.isnan(images)) > 0:\n",
    "    raise Exception('Movie contains nan! You did not remove enough borders')\n",
    "#%% correlation image\n",
    "Cn = cm.local_correlations(Y)\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "pl.imshow(Cn, cmap='gray', vmax=.35)\n",
    "#%% some parameter settings\n",
    "# order of the autoregressive fit to calcium imaging in general one (slow gcamps) or two (fast gcamps fast scanning)\n",
    "p = params_movie['p']  \n",
    "# merging threshold, max correlation allowed\n",
    "merge_thresh= params_movie['merge_thresh'] \n",
    "# half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "rf = params_movie['rf']  \n",
    "# amounpl.it of overlap between the patches in pixels\n",
    "stride_cnmf = params_movie['stride_cnmf'] \n",
    " # number of components per patch\n",
    "K =  params_movie['K'] \n",
    "# if dendritic. In this case you need to set init_method to sparse_nmf\n",
    "is_dendrites = params_movie['is_dendrites']\n",
    "# iinit method can be greedy_roi for round shapes or sparse_nmf for denritic data\n",
    "init_method = params_movie['init_method']\n",
    "# expected half size of neurons\n",
    "gSig = params_movie['gSig']  \n",
    "# this controls sparsity\n",
    "alpha_snmf = params_movie['alpha_snmf']  \n",
    "#frame rate of movie (even considering eventual downsampling)\n",
    "final_frate = params_movie['final_frate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> CNMF on patches </h1>\n",
    "<p> Our method builds upon and extend (Pnevmatikakis et al, Neuron, 2016)  <em> http://www.cell.com/neuron/fulltext/S0896-6273(15)01084-3 </em> </p>\n",
    "\n",
    "<p> <img src=\"docs/img/cnmf1.png\" /> </p>\n",
    "\n",
    "<p> We run portion of the CNMF algorithm  on patches </p>\n",
    "<p> We merge the patches with special attention to neurons on the border. </p>\n",
    "<p> We refine the result by rerunning CNMF on the whole movie </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params_movie['is_dendrites'] == True:\n",
    "    if params_movie['init_method'] is not 'sparse_nmf':\n",
    "        raise Exception('dendritic requires sparse_nmf')\n",
    "    if params_movie['alpha_snmf'] is None:\n",
    "        raise Exception('need to set a value for alpha_snmf')\n",
    "#%% Extract spatial and temporal components on patches\n",
    "t1 = time.time()\n",
    "cnm = cnmf.CNMF(n_processes, k=K, gSig=gSig, merge_thresh=0.8, p=0, dview=dview, Ain=None, rf=rf, stride=stride_cnmf, memory_fact=1,\n",
    "                method_init=init_method, alpha_snmf=alpha_snmf, only_init_patch=True, gnb=1, method_deconvolution='oasis')\n",
    "cnm = cnm.fit(images)\n",
    "\n",
    "A_tot = cnm.A\n",
    "C_tot = cnm.C\n",
    "YrA_tot = cnm.YrA\n",
    "b_tot = cnm.b\n",
    "f_tot = cnm.f\n",
    "sn_tot = cnm.sn\n",
    "t2 = time.time() - t1\n",
    "print(('Number of components:' + str(A_tot.shape[-1])))\n",
    "#%%\n",
    "pl.figure()\n",
    "crd = plot_contours(A_tot, Cn, thr=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>DISCARD LOW QUALITY COMPONENT </h1>\n",
    "<p> The patch dubdivision creates several spurious components that are not neurons </p>\n",
    "<p>We select the components according to criteria examining spatial and temporal components</p>\n",
    "<img src=\"docs/img/evaluationcomponent.png\"/>\n",
    "\n",
    "<p> Temporal components, for each trace: </p>\n",
    "\n",
    "<li>  compute the robust mode, corresponding to the baseline value</li>\n",
    "<li> use the values under the mode to estimate noise variance</li>\n",
    "<li> compute the probability of having large transients  given the noise distribution estimated </li>\n",
    "<li> Threshold on this probability s.t. some of the component are discarded because lacking large enough positive transients </li>\n",
    "\n",
    "<p> Spatial components, for each components: </p>\n",
    "\n",
    "<li> average the frames in the moveie where the neurons is active (from temporal component), this provides a nice image of the neuron</li>\n",
    "<li> compare this image with the corresponding spatial component (Person's correlation coefficient)</li>\n",
    "<li> threshold the correlation coefficient  </li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% DISCARD LOW QUALITY COMPONENT\n",
    "from caiman.components_evaluation import estimate_components_quality\n",
    "final_frate = params_movie['final_frate']\n",
    "r_values_min = .7  # threshold on space consistency\n",
    "fitness_min = -40  # threshold on time variability\n",
    "# threshold on time variability (if nonsparse activity)\n",
    "fitness_delta_min = -40\n",
    "Npeaks = 10\n",
    "traces = C_tot + YrA_tot\n",
    "idx_components, idx_components_bad = estimate_components_quality(\n",
    "    traces, Y, A_tot, C_tot, b_tot, f_tot, final_frate=final_frate, Npeaks=Npeaks, r_values_min=r_values_min, fitness_min=fitness_min, fitness_delta_min=fitness_delta_min)\n",
    "print(('Keeping ' + str(len(idx_components)) +\n",
    "       ' and discarding  ' + str(len(idx_components_bad))))\n",
    "#%%\n",
    "pl.figure(figsize=(20,10))\n",
    "crd = plot_contours(A_tot.tocsc()[:, idx_components], Cn, thr=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> CNMF full Field of View </h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "A_tot = A_tot.tocsc()[:, idx_components]\n",
    "C_tot = C_tot[idx_components]\n",
    "#%% rerun updating the components to refine\n",
    "cnm = cnmf.CNMF(n_processes, k=A_tot.shape, gSig=gSig, merge_thresh=merge_thresh, p=p, dview=dview, Ain=A_tot, Cin=C_tot,\n",
    "                f_in=f_tot, rf=None, stride=None, method_deconvolution='oasis')\n",
    "cnm = cnm.fit(images)\n",
    "#%%\n",
    "A, C, b, f, YrA, sn = cnm.A, cnm.C, cnm.b, cnm.f, cnm.YrA, cnm.sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Discard low quality components on full frame</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% again recheck quality of components, stricter criteria\n",
    "final_frate = params_movie['final_frate']\n",
    "r_values_min = .75\n",
    "fitness_min = - 50\n",
    "fitness_delta_min = - 50\n",
    "Npeaks = 10\n",
    "traces = C + YrA\n",
    "idx_components, idx_components_bad = estimate_components_quality(\n",
    "    traces, Y, A, C, b, f, final_frate=final_frate, Npeaks=Npeaks, r_values_min=r_values_min, fitness_min=fitness_min, fitness_delta_min=fitness_delta_min)\n",
    "print(' ***** ')\n",
    "print((len(traces)))\n",
    "print((len(idx_components)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% visualize included and excluded components\n",
    "pl.figure(figsize=(20,10))\n",
    "pl.subplot(1, 2, 1)\n",
    "crd = plot_contours(A.tocsc()[:, idx_components], Cn, thr=0.9)\n",
    "pl.subplot(1, 2, 2)\n",
    "crd = plot_contours(A.tocsc()[:, idx_components_bad], Cn, thr=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% visualize spatial and temporal components\n",
    "discard_traces_fluo=nb_view_patches(Yr,A.tocsc()[:,idx_components],C[idx_components],b,f,dims[0],dims[1],thr = 0.8,image_neurons=Cn, denoised_color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_traces_fluo=nb_view_patches(Yr,A.tocsc()[:,idx_components_bad],C[idx_components_bad],b,f,dims[0],dims[1],thr = 0.8,image_neurons=Cn, denoised_color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A.tocsc()[:, idx_components]), C[\n",
    "    idx_components, :], b, f, dims[0], dims[1], YrA=YrA[idx_components, :], img=Cn)\n",
    "#%%\n",
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A.tocsc()[:, idx_components_bad]), C[\n",
    "    idx_components_bad, :], b, f, dims[0], dims[1], YrA=YrA[idx_components_bad, :], img=Cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> closing, saving, and creating denoised version </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% save results\n",
    "np.savez(os.path.join(os.path.split(fname_new)[0], os.path.split(fname_new)[1][:-4] + 'results_analysis.npz'), Cn=Cn, A=A.todense(\n",
    "), C=C, b=b, f=f, YrA=YrA, sn=sn, d1=d1, d2=d2, idx_components=idx_components, idx_components_bad=idx_components_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% STOP CLUSTER and clean up log files\n",
    "cm.stop_server()\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "#%% reconstruct denoised movie\n",
    "denoised = cm.movie(A.dot(C) + b.dot(f)).reshape(dims+(-1,),order = 'F').transpose([2,0,1])\n",
    "#%% \n",
    "denoised.play(gain = 10, offset = 0,fr =100, magnification = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% reconstruct denoised movie without background\n",
    "denoised = cm.movie(A.dot(C)).reshape(dims+(-1,),order = 'F').transpose([2,0,1])\n",
    "#%%\n",
    "denoised.play(gain = 30, offset = 0,fr =100, magnification = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
